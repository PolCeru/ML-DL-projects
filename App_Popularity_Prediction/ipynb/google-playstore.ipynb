{"cells":[{"cell_type":"markdown","metadata":{"id":"-RSrtSLQPryH"},"source":["## Preliminary code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUVmB-jXPAMe"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["pip install tldextract"],"metadata":{"id":"rH19Hl4gCCwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H_ASykJVQDri"},"source":["## Load non processed file"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","data = pd.read_csv('/content/drive/MyDrive/Machine Learning/Google-Playstore_cleaned_V3.csv', encoding='utf-8', encoding_errors='replace')\n"],"metadata":{"id":"8aIMdiOEraXc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load processed file"],"metadata":{"id":"FuRYMEfbmD0x"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","data = pd.read_csv('/content/drive/MyDrive/Machine Learning/Google-Playstore_preprocessed.csv', encoding='utf-8', encoding_errors='replace')\n"],"metadata":{"id":"kphKkgUSeimu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696178907528,"user_tz":-120,"elapsed":368319,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"e8991e88-d9eb-445d-d32d-36931f8479b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Split your dataset into training and testing sets using stratified sampling\n","sample_size = 1000000  # Specify the desired sample size\n","X_sample, _, y_sample, _ = train_test_split(data, data['Minimum Installs'], train_size=sample_size, stratify=data['Minimum Installs'], random_state=42)\n","sampled_data = pd.DataFrame(data=X_sample, columns=data.columns)  # Assuming your data is in a DataFrame\n","sampled_data.to_csv('/content/drive/MyDrive/Machine Learning/sampled_data_1000000.csv', index=False)"],"metadata":{"id":"QZHB4s_o6R7r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YuKkmX9dPi7E"},"source":["## Preprocess"]},{"cell_type":"markdown","metadata":{"id":"nzbHCa7kazIh"},"source":["### General"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MqM5JkEtOejl","executionInfo":{"status":"error","timestamp":1695312106038,"user_tz":-120,"elapsed":12,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"colab":{"base_uri":"https://localhost:8080/","height":256},"outputId":"189784c9-129a-4544-dc40-b37a588b438c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e9b072384db5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop rows with NA values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Drop rows that are not in 'USD' and 'Currency' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Currency'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}],"source":["# Drop rows with NA values\n","data.dropna(inplace=True, axis=0)\n","\n","# Drop rows that are not in 'USD' and 'Currency' column\n","column='Currency'\n","data = data[data[column].isin(['USD'])]\n","data.drop(inplace=True, columns=column, axis=1)\n","\n","# Drop 'Installs' and 'Maximum Installs' columns\n","# data.drop(inplace=True, columns=['Installs', 'Maximum Installs'], axis=1)\n","\n","# Keep rows with 'Minimum Android' value containing 'and up' pattern\n","data = data[data['Minimum Android'].str.contains('and up')]"]},{"cell_type":"markdown","metadata":{"id":"NYCh_CnGbMz_"},"source":["### Dates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgcvzZ15bRn2"},"outputs":[],"source":["updated ='Updated'\n","last_updated='Last Updated'\n","released='Released'\n","\n","# Turn 'Last updated' string into 'Updated' boolean\n","\n","data[updated]                                           = False\n","data.loc[data[last_updated] == data[released], updated] = True\n","\n","data.drop(inplace=True, columns=last_updated, axis=1)\n","\n","# Turn 'Released' column into 'Month', 'Year' and 'MonthYear' columns\n","#released_split=data[released].str.split(expand=True)\n","\n","#data['Month']     = released_split[0]\n","#data['Year']      = released_split[2]\n","#data['MonthYear'] = released_split[0] + released_split[2]\n","\n","#data.drop(inplace=True, columns=released, axis=1)"]},{"cell_type":"markdown","metadata":{"id":"H7fi4HW-bSDM"},"source":["### URLs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OeTdf5HubUnX"},"outputs":[],"source":["# developer email => TLD + SLD (e.g.: com+ gmail)\n","#\tdeveloper website => TLD + SLD (e.g.: io + github)\n","import tldextract\n","\n","def extract_domains(elem):\n","  if \"@\" in elem:\n","      email_domain = elem.split('@', 1)[1]\n","      extracted = tldextract.extract(email_domain)\n","  else:\n","    extracted = tldextract.extract(elem)\n","  return extracted.domain, extracted.suffix\n","\n","data[['TLD', 'SLD']] = data['Developer Website'].apply(lambda elem: pd.Series(extract_domains(elem)))\n","data[['mailTLD', 'mailSLD']] = data['Developer Email'].apply(lambda elem: pd.Series(extract_domains(elem)))"]},{"cell_type":"code","source":["data.drop(inplace=True, columns=['Developer Website', 'Developer Email'], axis=1)"],"metadata":{"id":"xeC7rWywPg40"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T8xZ6tCQbZcJ"},"source":["### Strings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bp6mL1xlbbvd"},"outputs":[],"source":["def total_length(text):\n","    return len(text)\n","\n","data['TotalLength'] = data['App Name'].apply(total_length)\n","data.drop('App Name', axis = 1, inplace = True)\n","data.drop('App Id', axis = 1, inplace = True)"]},{"cell_type":"markdown","source":["### Factorization"],"metadata":{"id":"y6SydAzrzoaY"}},{"cell_type":"code","source":["data['Category'] = pd.factorize(data['Category'])[0]\n","data['Content Rating'] = pd.factorize(data['Content Rating'])[0]\n","data['Minimum Android'] = pd.factorize(data['Minimum Android'])[0]\n","data['Size'] = pd.factorize(data['Size'])[0]\n","data['Released_Month'] = pd.factorize(data['Released_Month'])[0]\n","data['Released_Year'] = pd.factorize(data['Released_Year'])[0]\n","data['Released'] = pd.factorize(data['Released'])[0]\n","data['Rating Count'] = pd.factorize(data['Rating Count'])[0]\n","data['TLD'] = pd.factorize(data['TLD'])[0]\n","data['SLD'] = pd.factorize(data['SLD'])[0]\n","data['mailTLD'] = pd.factorize(data['mailTLD'])[0]\n","data['mailSLD'] = pd.factorize(data['mailSLD'])[0]"],"metadata":{"id":"NsvDobzSzslU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data.head)"],"metadata":{"id":"UYcskPSEUgKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.to_csv('/content/drive/MyDrive/Machine Learning/Google-Playstore_preprocessed.csv', index=False)"],"metadata":{"id":"MNtYdsTA-8vF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dummy Test"],"metadata":{"id":"YJH17BZ05vl_"}},{"cell_type":"code","source":["from sklearn.dummy import DummyClassifier\n","from sklearn.metrics import accuracy_score\n","\n","train_data = data.sample(frac=0.80)\n","test_data = data.drop(train_data.index)\n","val_data = test_data.sample(frac=0.5)\n","test_data = test_data.drop(val_data.index)\n","\n","train_label = train_data['Minimum Installs']\n","val_label = val_data['Minimum Installs']\n","test_label = test_data['Minimum Installs']\n","\n","dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n","dummy_classifier.fit(train_data, train_label)\n","\n","y_pred = dummy_classifier.predict(test_data)\n","accuracy = accuracy_score(test_label, y_pred)\n","\n","print(f\"Accuracy: {accuracy:.5f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApghZuUBdPut","executionInfo":{"status":"ok","timestamp":1695316181070,"user_tz":-120,"elapsed":955,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"2b8635f1-ec13-4ab2-cf7c-e2d42927b3d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.19304\n"]}]},{"cell_type":"markdown","source":["\n","\n","\n","\n","## CART"],"metadata":{"id":"MTBMFQyl6DpQ"}},{"cell_type":"markdown","source":["### No parameter tuning"],"metadata":{"id":"4qn16XYg7Apb"}},{"cell_type":"code","source":["from numpy                   import median\n","from sklearn                 import tree\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Split into training and test data\n","train_data, test_data, train_targets, test_targets = train_test_split(data.drop('Minimum Installs', axis=1), data['Minimum Installs'],test_size=0.2, stratify=data['Minimum Installs'])\n","score_train = 0\n","score_test  = 0\n","trials = 3\n","\n","score_list_train = []\n","score_list_test  = []\n","\n","clf = tree.DecisionTreeClassifier()\n","\n","for i in range(0, trials):\n","    clf = clf.fit(train_data, train_targets)\n","    score_list_train.append(clf.score(train_data, train_targets))\n","    score_list_test.append(clf.score(test_data, test_targets))\n","    score_train += clf.score(train_data, train_targets)\n","    score_test  += clf.score(test_data, test_targets)\n","    print(str(i) + \" \", end='')\n"],"metadata":{"id":"PT9UjceU7okq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695740163600,"user_tz":-120,"elapsed":105377,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"3b704c40-d811-40dc-d557-b1bd8dbe1e99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 1 2 "]}]},{"cell_type":"code","source":["print('train avg ' + str(median(score_list_train)) + 'train med ' + str(score_train/trials) +\n","      'test avg ' + str(median(score_list_test)) + 'test med ' + str(score_test/trials))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzvKRYQ_Z5hj","executionInfo":{"status":"ok","timestamp":1695740163601,"user_tz":-120,"elapsed":27,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"49e5c460-30b5-43e4-db26-1e321a60d5d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train avg 0.9808795702992147train med 0.9808795702992147test avg 0.33840631827495893test med 0.3385861231357968\n"]}]},{"cell_type":"markdown","source":["### With Tuning"],"metadata":{"id":"8JKcCOoH7Zep"}},{"cell_type":"code","source":["from sklearn                 import tree\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n","\n","# Split into training and test data\n","train_data, test_data, train_targets, test_targets = train_test_split(data.drop('Minimum Installs', axis=1), data['Minimum Installs'],test_size=0.2, stratify=data['Minimum Installs'])\n","\n"],"metadata":{"id":"LlWxDekjv4p-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["With this test we find that 13 as max_depth is the best choice"],"metadata":{"id":"HmKpBxSW8gTc"}},{"cell_type":"code","source":["score_train = 0\n","score_test  = 0\n","trials = 10\n","\n","#13 best depth\n","for i in range(0, trials):\n","  clf = tree.DecisionTreeClassifier(max_depth = 10+i)\n","  clf = clf.fit(train_data, train_targets)\n","  score_train = clf.score(train_data, train_targets)\n","  score_test  = clf.score(test_data, test_targets)\n","  print(str(i + 10) + \" score train: \" + str(score_train) + \"\\tscore_test: \" + str(score_test))\n"],"metadata":{"id":"FrGLQ4nV9Bdx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695740331359,"user_tz":-120,"elapsed":166527,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"3c6ffb74-bffe-40bf-bb38-5c566c17ca0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10 score train: 0.44947173706355864\tscore_test: 0.4458176710860214\n","11 score train: 0.45412038305317914\tscore_test: 0.447720888575267\n","12 score train: 0.46018626813213653\tscore_test: 0.44883364318573504\n","13 score train: 0.4674166470888077\tscore_test: 0.44856223962220626\n","14 score train: 0.4770455611410174\tscore_test: 0.4478973008915607\n","15 score train: 0.4894572169359647\tscore_test: 0.44615692554043235\n","16 score train: 0.5048661934620412\tscore_test: 0.4429781113026014\n","17 score train: 0.5243725260866136\tscore_test: 0.43824890420811224\n","18 score train: 0.548044914011499\tscore_test: 0.4316979006934361\n","19 score train: 0.5755067838341449\tscore_test: 0.4246210527744229\n"]}]},{"cell_type":"markdown","source":["Try with RandomizedSearchCV"],"metadata":{"id":"Uo2Apgrt9EoP"}},{"cell_type":"code","source":["clf = tree.DecisionTreeClassifier()\n","\n","# Define the hyperparameter distributions\n","param_dist = {\n","    'criterion': ['gini', 'entropy'],\n","    'max_depth': [None, 5, 10, 13, 15, 20],  # None for no maximum depth\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Create a RandomizedSearchCV object\n","random_search = RandomizedSearchCV(\n","    clf,\n","    param_distributions=param_dist,\n","    n_iter=10,    # Number of random parameter combinations to try\n","    cv=5,         # Number of cross-validation folds\n","    random_state=42\n",")\n","\n","# Perform Randomized Hyperparameter Search\n","random_search.fit(train_data, train_targets)\n","\n","# Find the Best Parameters\n","best_params = random_search.best_params_\n","best_clf = random_search.best_estimator_\n","\n","# Evaluate the Model on the Test Data\n","accuracy = best_clf.score(test_data, test_targets)\n","\n","print(\"Best Hyperparameters:\", best_params)\n","print(\"Accuracy on Test Data:\", accuracy)"],"metadata":{"id":"PNivE38m8w8U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695741100876,"user_tz":-120,"elapsed":769538,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"6985f031-7724-44e9-9f42-fec0a6fa5c19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 13, 'criterion': 'entropy'}\n","Accuracy on Test Data: 0.44982765873715924\n"]}]},{"cell_type":"code","source":["train_accuracy = best_clf.score(train_data, train_targets)\n","print(\"Train Accuracy:\", train_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Elt7GWCGl20","executionInfo":{"status":"ok","timestamp":1695741101273,"user_tz":-120,"elapsed":407,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"4da1beab-b633-403a-cbaf-6c64d45c03b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Accuracy: 0.4625398518980911\n"]}]},{"cell_type":"markdown","source":["Try with GridSearchCV"],"metadata":{"id":"4XLPB5SbH3mr"}},{"cell_type":"code","source":["clf = tree.DecisionTreeClassifier()\n","\n","# Define the hyperparameter distributions\n","param_grid = {\n","    'criterion': ['gini', 'entropy'],\n","    'max_depth': [None, 5, 10, 13, 15, 20],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","grid_search = GridSearchCV(clf, param_grid, cv=5)\n","grid_search.fit(train_data, train_targets)\n","\n","# Find the Best Parameters\n","best_params = grid_search.best_params_\n","best_clf = grid_search.best_estimator_\n","\n","# Evaluate the Model on the Test Data\n","accuracy = best_clf.score(test_data, test_targets)\n","\n","print(\"Best Hyperparameters:\", best_params)\n","print(\"Accuracy on Test Data:\", accuracy)"],"metadata":{"id":"QwZVfj0iHg9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_accuracy = best_clf.score(train_data, train_targets)\n","print(\"Train Accuracy:\", train_accuracy)"],"metadata":{"id":"W5DUNAX_IVmw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A more sophisticated approach with RandomizedSearchCV"],"metadata":{"id":"mRVc-z1wfpwN"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline\n","\n","# Split the data into training (80%), validation (10%), and test (10%) sets\n","X_train, X_temp, y_train, y_temp = train_test_split(\n","  data.drop('Minimum Installs', axis=1),\n","  data['Minimum Installs'],\n","  test_size=0.2,\n","  random_state=42,\n","  stratify=data['Minimum Installs']  # Stratified split for class balance\n",")\n","\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_temp,\n","    y_temp,\n","    test_size=0.5,\n","    random_state=42,\n","    stratify=y_temp  # Stratified split for class balance\n",")\n","\n","# 1. Data Preprocessing\n","# Standardize features (useful for some models, not needed for Decision Trees)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# 2. Feature Selection\n","# Use SelectKBest with ANOVA F-statistic for feature selection (adjust k as needed)\n","selector = SelectKBest(score_func=f_classif, k=10)\n","X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n","X_val_selected = selector.transform(X_val_scaled)\n","X_test_selected = selector.transform(X_test_scaled)\n","\n","# 3. Decision Tree Model with Cross-Validation\n","clf = DecisionTreeClassifier(random_state=42)\n","\n","# Perform 5-fold cross-validation on the training data\n","cv_scores = cross_val_score(clf, X_train_selected, y_train, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n","print(\"Cross-Validation Scores:\", cv_scores)\n","print(\"Mean CV Score:\", np.mean(cv_scores))\n","\n","# 4. Hyperparameter Tuning (RandomizedSearchCV)\n","param_dist = {\n","    'criterion': ['gini', 'entropy'],\n","    'max_depth': [13],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","random_search = RandomizedSearchCV(\n","    clf,\n","    param_distributions=param_dist,\n","    n_iter=10,\n","    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n","    random_state=42,\n","    n_jobs=-1  # Use all available CPU cores\n",")\n","\n","random_search.fit(X_train_selected, y_train)\n","\n","print(\"Best Hyperparameters:\", random_search.best_params_)\n","\n","# 5. Final Model Evaluation on Test Data\n","best_clf = random_search.best_estimator_\n","y_pred = best_clf.predict(X_test_selected)\n","test_accuracy = accuracy_score(y_test, y_pred)\n","print(\"Test Accuracy:\", test_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NM50IykVNGld","executionInfo":{"status":"ok","timestamp":1695741591940,"user_tz":-120,"elapsed":490675,"user":{"displayName":"Paolo Cerutti","userId":"09557360214692032501"}},"outputId":"88371ab2-e671-4108-b547-72b3054e3a88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross-Validation Scores: [0.32373808 0.32639699 0.32522656 0.32532971 0.32472329]\n","Mean CV Score: 0.3250829266259918\n","Best Hyperparameters: {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 13, 'criterion': 'entropy'}\n","Test Accuracy: 0.44179750580125116\n"]}]},{"cell_type":"markdown","source":["## Random Forest"],"metadata":{"id":"mKFvZKFgfwwA"}},{"cell_type":"code","source":["#!/usr/bin/python3\n","\n","from pandas                  import read_csv\n","from sklearn                 import tree\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble        import RandomForestClassifier\n","from sklearn.metrics         import accuracy_score\n","\n","#PUT THE RIGHT DATASET\n","#data = read_csv(\"./preprocessed.csv\")\n","\n","# Split the data into training and testing sets\n","X_train,X_test,y_train,y_test = train_test_split(data.drop('Minimum Installs', axis=1),\n","                                                 data['Minimum Installs'],\n","                                                 test_size=0.2,\n","                                                 random_state=42,\n","                                                 stratify=data['Minimum Installs']  # Stratified split for class balance\n","                                                 )\n","\n","# Create a Random Forest Classifier\n","rf_model = RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1)\n","\n","# Define a parameter grid for Grid Search\n","param_grid = {\n","    'max_depth': [3, 4, 5, 6, 10, 12, 15],\n","}\n","\n","# Perform Grid Search with cross-validation\n","grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best max_depth from Grid Search\n","best_max_depth = grid_search.best_params_['max_depth']\n","print(\"Best max_depth:\", best_max_depth)\n","\n","rf_model = RandomForestClassifier(max_depth=best_max_depth, random_state=42, verbose=1, n_jobs=-1)\n","\n","#Retrain Again\n","param_grid = {\n","    'n_estimators': [30, 50, 100, 500],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","grid_search = GridSearchCV(max estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters from Grid Search\n","best_params = grid_search.best_params_\n","print(\"Best Parameters:\", best_params)\n","\n","# Create a Random Forest model with the best parameters\n","best_rf_model = RandomForestClassifier(random_state=42, **best_params, verbose=1, n_jobs=-1)\n","\n","# Train the model with the best parameters on the entire training set\n","best_rf_model.fit(X_train, y_train)\n","\n","# Test\n","y_pred = best_rf_model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Train\n","y_train_pred = best_rf_model.predict(X_train)\n","test_accuracy = accuracy_score(y_train, y_train_pred)\n","print(\"Train accuracy:\", train_accuracy)\n"],"metadata":{"id":"yMlmZPJonl5P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGBoost"],"metadata":{"id":"rkPZCPmsGbd2"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n","\n","\n","# Function to determine the value mapping\n","def determine_mapping(values):\n","    unique_values = sorted(smaller_dataset['Minimum Installs'].unique())\n","    mapping = {val: idx for idx, val in enumerate(unique_values)}\n","    return mapping\n","\n","# Get the mapping dictionary\n","value_mapping = determine_mapping(smaller_dataset['Minimum Installs'])\n","\n","# Use the replace method to map the values in the 'values' column\n","smaller_dataset['Minimum Installs'] = smaller_dataset['Minimum Installs'].replace(value_mapping)\n","unique_values = smaller_dataset['Minimum Installs'].unique()\n","sorted_unique_values = sorted(unique_values)\n","\n","# Define the target variable\n","target = 'Minimum Installs'\n","\n","# List of predictors (exclude the target column)\n","predictors = [col for col in smaller_dataset.columns if col != 'Minimum Installs']\n","\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(smaller_dataset[predictors],\n","                                                    smaller_dataset['Minimum Installs'],\n","                                                    test_size=0.2,\n","                                                    random_state=42,\n","                                                    stratify=smaller_dataset['Minimum Installs'])\n","\n","# Handle missing values in y_train (choose one of the methods mentioned above)\n","# For example, removing rows with missing values:\n","X_train = X_train[~y_train.isnull()]\n","y_train = y_train.dropna()\n","\n","# Define the XGBoost Classifier\n","xgb_classifier = XGBClassifier(\n","    learning_rate =0.2,\n","    n_estimators=70,\n","    gamma=0,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    device = \"cuda\",\n","    nthread=64,\n","    seed=27\n",")\n","\n","# Define a parameter grid for Grid Search\n","param_grid = {\n","    'max_depth':[3,4,5,6],\n","    'min_child_weight':[4,5,6,8,10,12]\n","}\n","\n","# Create a Grid Search with cross-validation\n","grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)\n","\n","# Fit the Grid Search to your training data\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and best score\n","best_params_1 = grid_search.best_params_\n","best_score_1 = grid_search.best_score_\n","\n","\n","print(\"Best Parameters:\", best_params_1)\n","print(\"Best Accuracy Score:\", best_score_1)\n","\n","# Define the XGBoost Classifier\n","xgb_classifier = XGBClassifier(\n","    learning_rate=0.2,\n","    n_estimators=70,\n","    max_depth=best_params_1['max_depth'],\n","    min_child_weight=best_params_1['min_child_weight'],\n","    device = \"cuda\",\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    nthread=64,\n","    seed=27\n",")\n","\n","# Define a parameter grid for Grid Search\n","param_grid = {\n","    'gamma':[i/10.0 for i in range(0,5)]\n","}\n","\n","# Create a Grid Search with cross-validation\n","grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)\n","\n","# Fit the Grid Search to your training data\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and best score\n","best_params_2 = grid_search.best_params_\n","best_score_2 = grid_search.best_score_\n","\n","print(\"Best Parameters:\", best_params_2)\n","print(\"Best Accuracy Score:\", best_score_2)\n","\n","# Define the XGBoost Classifier\n","xgb_classifier = XGBClassifier(\n","    learning_rate =0.1,\n","    n_estimators=100,\n","    max_depth=best_params_1['max_depth'],\n","    min_child_weight=best_params_1['min_child_weight'],\n","    gamma=best_params_2['gamma'],\n","    device = \"cuda\",\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    nthread=64,\n","    seed=27\n",")\n","\n","# Define a parameter grid for Grid Search\n","param_grid = {\n","    'subsample':[i/10.0 for i in range(6,10)],\n","    'colsample_bytree':[i/10.0 for i in range(6,10)]\n","}\n","\n","# Create a Grid Search with cross-validation\n","grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)\n","\n","# Fit the Grid Search to your training data\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and best score\n","best_params_3 = grid_search.best_params_\n","best_score_3 = grid_search.best_score_\n","\n","print(\"Best Parameters:\", best_params_3)\n","print(\"Best Accuracy Score:\", best_score_3)\n","\n","# Define the XGBoost Classifier\n","xgb_classifier = XGBClassifier(\n","    learning_rate =0.1,\n","    n_estimators=100,\n","    max_depth=best_params_1['max_depth'],\n","    min_child_weight=best_params_1['min_child_weight'],\n","    gamma=best_params_2['gamma'],\n","    subsample=best_params_3['subsample'],\n","    colsample_bytree=best_params_3['colsample_bytree'],\n","    device = \"cuda\",\n","    nthread=64,\n","    seed=27\n",")\n","\n","# Define a parameter grid for Grid Search\n","param_grid = {\n","    'reg_alpha':[1e-5, 1e-2,0.05, 0.1, 0.5, 1, 100]\n","}\n","\n","# Create a Grid Search with cross-validation\n","grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)\n","\n","# Fit the Grid Search to your training data\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and best score\n","best_params_4 = grid_search.best_params_\n","best_score_4 = grid_search.best_score_\n","\n","\n","print(\"Best Parameters:\", best_params_4)\n","print(\"Best Accuracy Score:\", best_score_4)\n","\n","\n","# Function to determine the value mapping\n","def determine_mapping(values):\n","    unique_values = sorted(dataset['Minimum Installs'].unique())\n","    mapping = {val: idx for idx, val in enumerate(unique_values)}\n","    return mapping\n","\n","# Get the mapping dictionary\n","value_mapping = determine_mapping(dataset['Minimum Installs'])\n","\n","# Use the replace method to map the values in the 'values' column\n","dataset['Minimum Installs'] = dataset['Minimum Installs'].replace(value_mapping)\n","unique_values = dataset['Minimum Installs'].unique()\n","sorted_unique_values = sorted(unique_values)\n","\n","# Define the target variable\n","target = 'Minimum Installs'\n","\n","# List of predictors (exclude the target column)\n","predictors = [col for col in dataset.columns if col != 'Minimum Installs']\n","\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(dataset[predictors],\n","                                                    dataset['Minimum Installs'],\n","                                                    test_size=0.2,\n","                                                    random_state=42,\n","                                                    stratify=dataset['Minimum Installs'])\n","\n","\n","# Train the final model with the best parameters\n","final_xgb_model = XGBClassifier(\n","    n_estimators=1000,\n","    max_depth=best_params_1['max_depth'],\n","    min_child_weight=best_params_1['min_child_weight'],\n","    gamma=best_params_2['gamma'],\n","    subsample=best_params_3['subsample'],\n","    colsample_bytree=best_params_3['colsample_bytree'],\n","    reg_alpha=best_params_4['reg_alpha'],\n","    device = \"cuda\",\n","    learning_rate=0.1,\n","    nthread=64,\n","    seed=27\n",")\n","final_xgb_model.fit(X_train, y_train)\n","\n","# Evaluate the final model on the test data\n","y_pred = final_xgb_model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy on Test Data:\", accuracy)\n","\n","# Train the final model with the best parameters\n","final_final_xgb_model = XGBClassifier(\n","    n_estimators=5000,\n","    max_depth=best_params_1['max_depth'],\n","    min_child_weight=best_params_1['min_child_weight'],\n","    gamma=best_params_2['gamma'],\n","    subsample=best_params_3['subsample'],\n","    colsample_bytree=best_params_3['colsample_bytree'],\n","    reg_alpha=best_params_4['reg_alpha'],\n","    device = \"cuda\",\n","    learning_rate=0.01,\n","    nthread=64,\n","    seed=27\n",")\n","final_final_xgb_model.fit(X_train, y_train)\n","\n","# Evaluate the final model on the test data\n","y_pred = final_final_xgb_model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy on Test Data:\", accuracy)\n","\n","# Confusion Matrix\n","confusion_mat = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\\n\", confusion_mat)\n","\n","# Classification Report\n","class_report = classification_report(y_test, y_pred, output_dict=True)\n","print(\"Classification Report:\\n\", class_report)\n","\n","# ROC Curve and AUC\n","y_probs = final_final_xgb_model.predict_proba(X_test)[:, 1]\n","fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n","roc_auc = auc(fpr, tpr)\n","\n","print(\"False Positive Rate (FPR):\", fpr)\n","print(\"True Positive Rate (TPR):\", tpr)\n","print(\"Thresholds:\", thresholds)\n","print(\"Area Under the Curve (AUC):\", roc_auc)"],"metadata":{"id":"gctJkktoGpLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the final model with the best parameters\n","final_final_xgb_model = XGBClassifier(\n","    n_estimators=5000,\n","    max_depth=best_params_1['max_depth'],\n","    min_child_weight=best_params_1['min_child_weight'],\n","    gamma=best_params_2['gamma'],\n","    subsample=best_params_3['subsample'],\n","    colsample_bytree=best_params_3['colsample_bytree'],\n","    reg_alpha=best_params_4['reg_alpha'],\n","    learning_rate=0.01,\n","    device=cuda:0\n","    nthread=64,\n","    seed=27\n",")\n","final_final_xgb_model.fit(X_train, y_train)\n","\n","# Evaluate the final model on the test data\n","y_pred = final_final_xgb_model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy on Test Data:\", accuracy)\n","\n","# Confusion Matrix\n","confusion_mat = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\\n\", confusion_mat)\n","\n","# Classification Report\n","class_report = classification_report(y_test, y_pred, output_dict=True)\n","print(\"Classification Report:\\n\", class_report)\n","\n","# ROC Curve and AUC\n","y_probs = final_final_xgb_model.predict_proba(X_test)[:, 1]\n","fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n","roc_auc = auc(fpr, tpr)\n","\n","print(\"False Positive Rate (FPR):\", fpr)\n","print(\"True Positive Rate (TPR):\", tpr)\n","print(\"Thresholds:\", thresholds)\n","print(\"Area Under the Curve (AUC):\", roc_auc)"],"metadata":{"id":"TPcqM30W81TD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["/cluster/datastore/paoloc/.local/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:34:31] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","  warnings.warn(smsg, UserWarning)\n","\n","\n","\n","\n","  /cluster/datastore/paoloc/.local/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:34:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\n","    E.g. tree_method = \"hist\", device = \"cuda\"\n","\n","  warnings.warn(smsg, UserWarning)\n","/cluster/datastore/paoloc/.local/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:34:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\n","    E.g. tree_method = \"hist\", device = \"cuda\"\n","\n","  warnings.warn(smsg, UserWarning)\n","/cluster/datastore/paoloc/.local/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [16:34:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","Potential solutions:\n","- Use a data structure that matches the device ordinal in the booster.\n","- Set the device for booster before call to inplace_predict.\n","\n","This warning will only be shown once."],"metadata":{"id":"SGG1JJB0OOXM"}}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["H_ASykJVQDri","YuKkmX9dPi7E","YJH17BZ05vl_"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}